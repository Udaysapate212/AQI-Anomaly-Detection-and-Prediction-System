{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cdc044d",
   "metadata": {},
   "source": [
    "# üåç Comprehensive AQI Anomaly Detection & Explainable AI System\n",
    "\n",
    "## Project Overview\n",
    "This notebook implements a complete AI/ML system for:\n",
    "- **Real-time air quality anomaly detection** using ensemble methods\n",
    "- **Predictive modeling** with advanced machine learning algorithms\n",
    "- **Explainable AI** using SHAP and LIME frameworks\n",
    "- **Interactive visualizations** and production-ready pipelines\n",
    "\n",
    "**Dataset:** Air Quality Index (AQI) data from 26 Indian cities (2015-2020)\n",
    "\n",
    "**Key Features:**\n",
    "- üîç Multi-algorithm anomaly detection (Isolation Forest, LOF, Z-score)\n",
    "- üìä Advanced time series analysis and feature engineering\n",
    "- ü§ñ Ensemble predictive modeling (Random Forest, XGBoost, Voting Regressor)\n",
    "- üî¨ Explainable AI with SHAP and LIME\n",
    "- üìà Comprehensive model evaluation and comparison\n",
    "- üöÄ Production-ready prediction pipeline\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e4044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Machine Learning - Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Machine Learning - Models\n",
    "from sklearn.ensemble import IsolationForest, RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Machine Learning - Evaluation\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Explainable AI\n",
    "import shap\n",
    "from lime import lime_tabular\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"üìä Pandas version: {pd.__version__}\")\n",
    "print(f\"üî¢ NumPy version: {np.__version__}\")\n",
    "print(f\"ü§ñ Scikit-learn ready for ML tasks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3d3ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Summary\n",
    "print(\"=\"*80)\n",
    "print(\"üìä STATISTICAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Numerical columns summary\n",
    "df.describe().T.style.background_gradient(cmap='YlOrRd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff02f7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Information\n",
    "print(\"=\"*80)\n",
    "print(\"üìã DATASET INFORMATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n{'Column Name':<20} {'Data Type':<15} {'Non-Null Count':<15} {'Null Count':<15} {'Null %'}\")\n",
    "print(\"-\"*85)\n",
    "\n",
    "for col in df.columns:\n",
    "    non_null = df[col].notna().sum()\n",
    "    null_count = df[col].isna().sum()\n",
    "    null_pct = (null_count / len(df)) * 100\n",
    "    dtype = str(df[col].dtype)\n",
    "    print(f\"{col:<20} {dtype:<15} {non_null:<15} {null_count:<15} {null_pct:.2f}%\")\n",
    "\n",
    "print(f\"\\nüíæ Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(f\"üî¢ Total Data Points: {df.shape[0] * df.shape[1]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56013f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the AQI dataset\n",
    "dataset_path = '../data/dataset.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    print(\"‚úÖ Dataset loaded successfully!\")\n",
    "    print(f\"üìã Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "    print(f\"üìÖ Date range: {df['Date'].min()} to {df['Date'].max()}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Dataset not found. Trying alternative path...\")\n",
    "    dataset_path = '../../dataset.csv'\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    print(\"‚úÖ Dataset loaded from alternative path!\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä DATASET PREVIEW (First 5 rows)\")\n",
    "print(\"=\"*80)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc32bfe3",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Project Setup and Data Loading\n",
    "\n",
    "Let's start by importing all necessary libraries and loading our AQI dataset."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
